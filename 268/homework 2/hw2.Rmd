---
title: "AMS 268 - HW #2"
author: "Raquel Barata"
output: beamer_presentation
---

```{r, include=FALSE}
library(mnormt)
library(randomForest)
library(BayesTree)
source('~/Google Drive/year 3/268/homework 2/gprior_regression.R')
#sample size
nn = 1:2
all.n = c(50,200)
#beta size
np = 1
all.p = c(20)
#beta covariance
nS = 2
S2 = function(p){Sig = diag(p)
for(r in 1:p){
  for(c in 1:p){
    Sig[r,c] = (0.6)^(abs(r-c))}}
return(Sig)}
#beta values
nB = 1
```

# g-prior
```{r, echo=FALSE}
par(mfrow=c(2,2))
# load datasets
for(i in nn){
  n = all.n[i]
  p = 20
        
  setwd("~/Google Drive/year 3/268/homework 2")
  load(sprintf("dat_n%s_p20_S2_B1.Rda",n))
  
  gp = gprior_regression(dat$y,dat$X)
  #save needed values for next parts E(beta|y), MSE
  ub.beta = apply(gp$ps.beta,1,function(x) quantile(x,0.975))
  lb.beta = apply(gp$ps.beta,1,function(x) quantile(x,0.025))
  p.mean.beta = rowMeans(gp$ps.beta)
  include.zero.indicator = as.numeric(lb.beta <= 0)*as.numeric(ub.beta >= 0)
  interval.cols = rep("grey",p)
  interval.cols[which(include.zero.indicator==1)] = "blue"
  MSE = mean( (dat$B-p.mean.beta)^2 )

  par(mar=c(4,4,1,1))
  plot(dat$B,col="red",pch=19,xlab="predictor index",ylab="coefficents",cex.axis=1,cex.lab=1,ylim=c(-1.5,4),xlim=c(-0.2,20.2))
  arrows(1:p, lb.beta, 1:p,  ub.beta, length=0.01, angle=90, code=3, lwd=2, col=interval.cols)
  points(1:p, p.mean.beta, pch=19, lwd=1, col="black", cex=.5)
  #polygon(c(1:p, rev(1:p)), c(ub.beta, rev(lb.beta) ),col="grey", border = NA)
  points(dat$B,col="red",pch=19,lwd=1,cex=.5)
  legend("topright",legend = c(sprintf("n=%s",n),sprintf("MSE=%s",round(MSE,3))),cex=0.8,inset=0.04,box.lty=0)
}

```

- g fixed as $\text{max}\{n,p^2\}$ respectively for each model.
- True $\beta_j$ values in red. 95% posterior intervals in grey if interval does not include zero, blue if interval does include zero.
- Test $H_0: \beta_1 = 0$ -> Reject $H_0$ since 95% PI does not include $0$.
- Test $H_0: \beta_{10} = 0$ -> Fail to reject $H_0$ since 95% PI does include $0$.

\newpage

# Random Forest vs. BART: $n=200$, $p=200$
```{r, echo=FALSE}
par(mfrow=c(2,2))
n = 200
p = 200
load(sprintf("dat2i_n%s_p%s.Rda",n,p))

# RF with 10 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=10)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 10 trees")
        
# RF with 500 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=500)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 500 trees")

# BART with 10 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 10
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 10 trees")
        
# BART with 500 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 500
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 500 trees")


```

\newpage

# Random Forest vs. BART: $p=100$, $n=500$
```{r, echo=FALSE}
par(mfrow=c(2,2))
n = 500
p = 100
load(sprintf("dat2ii_n%s_p%s.Rda",n,p))

# RF with 10 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=10)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 10 trees")
        
# RF with 500 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=500)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 500 trees")

# BART with 10 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 10
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 10 trees")
        
# BART with 500 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 500
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 500 trees")

```

\newpage

# Random Forest vs. BART with added noise to $x_1$, $x_2$, and $x_9$: $p=200$, $n=200$
```{r, echo=FALSE}
par(mfrow=c(2,2))
n = 200
p = 200
load(sprintf("dat2i_noise_n%s_p%s.Rda",n,p))

# RF with 10 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=10)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 10 trees")
        
# RF with 500 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=500)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 500 trees")

# BART with 10 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 10
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 10 trees")
        
# BART with 500 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 500
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 500 trees")


```

\newpage 

# Random Forest vs. BART with added noise to $x_1$, $x_2$, and $x_9$: $p=100$, $n=500$
```{r, echo=FALSE}
par(mfrow=c(2,2))
n = 500
p = 100
load(sprintf("dat2ii_noise_n%s_p%s.Rda",n,p))

# RF with 10 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=10)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 10 trees")
        
# RF with 500 trees
y = dat$y
X = dat$X
df = data.frame(y,X)
names(df) <- make.names(names(df))
CRForest <- randomForest(dat$y~.,data=df,mtry=max(floor(ncol(dat$X)/3),1),ntree=500)
Cpredicted.test <- predict(CRForest,data.frame(dat$X.test),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
Cpredicted.train <- predict(CRForest,data.frame(dat$X),type="response",norm.votes=TRUE,predict.all=TRUE, proximity=FALSE,nodes=FALSE)
MSPE.out = mean((as.numeric(Cpredicted.test$aggregate)-dat$y.test)^2)
#MSPE.in = mean((as.numeric(Cpredicted.train$aggregate)-dat$y)^2)

ub.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.975))
lb.y = apply(Cpredicted.test$individual,1,function(x) quantile(x,0.025))
p.mean.y = as.numeric(Cpredicted.test$aggregate)
length = mean(ub.y-lb.y)
coverage = length(intersect(which(dat$y.test>lb.y),which(dat$y.test<ub.y)))/100

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("Random Forest, 500 trees")

# BART with 10 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 10
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 10 trees")
        
# BART with 500 trees
post.burn.in <- 3000
burn.in <- 1000
num.tree <- 500
power.par.tree.prior <- 2
base.par.tree.prior <- 0.95
RT.BART <- bart(dat$X, dat$y, dat$X.test,sigest=2, sigdf=3, sigquant=.90,
                k=2.0,power=power.par.tree.prior,base=base.par.tree.prior,
                binaryOffset=0,ntree=num.tree,
                ndpost=post.burn.in, nskip=burn.in, keepevery=1,
                keeptrainfits=TRUE,usequants=FALSE, numcut=100, printcutoffs=0,
                verbose=FALSE)

ytest.BART <- RT.BART$yhat.test ##posterior predictive samples at test covaraites
quant.BART <- apply(ytest.BART,2,quantile,c(.025,.975))
length <- mean(quant.BART[2,]-quant.BART[1,])
coverage <- length(intersect(which(dat$y.test>quant.BART[1,]),which(dat$y.test<quant.BART[2,])))/100
MSPE.out <- mean((dat$y.test-colMeans(ytest.BART))^2)

p.mean.y = colMeans(ytest.BART)
ub.y = quant.BART[2,]
lb.y = quant.BART[1,]

par(mar=c(4,4,1,1))
plot(dat$y.test,col="red",pch=19,xlab="response index",ylab="new responses, y",cex.axis=1,cex.lab=1,xlim=c(-0.2,100.2),ylim=c(-50,300))
        arrows(1:100, lb.y, 1:100,  ub.y, length=0.01, angle=90, code=3, lwd=2, col="grey")
        points(1:100, p.mean.y, pch=19, lwd=1, col="black", cex=.5)
        #polygon(c(1:50, rev(1:50)), c(ub.y, rev(lb.y) ),col="grey", border = NA)
        #lines(p.mean.y,lwd=0.6)
        legend("topright",legend = c(sprintf("out MSPE=%s",round(MSPE.out,3)),sprintf("length=%s",round(length,3)),sprintf("coverage=%s",round(coverage,3))),cex=0.8,inset=0.04,box.lty=0)
        points(dat$y.test,col="red",pch=19,lwd=1,cex=.5)
        title("BART, 500 trees")

```

\newpage

# Random Forest vs. BART
- All BART models fit with post-burn-in samples of 3000 and burn-in of 1000
- 95% posterior predicive intervals for 100 new predictors in grey, $y_{est,i}$ in black, and true values $y_{pred,i}$ in red.
- out-of-sample MSPE = $\frac{1}{100}\sum_{i=1}^{50}(y_{pred,i} - y_{est,i})^2$
- "length" is the average length of the 95% predictive intervals
- "coverage" is the proportion of 95% predictive intervals which contain the true values $y_{pred,i}$.


